{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b4cbe7d",
   "metadata": {},
   "source": [
    "# Machine learning basics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c4da3b8",
   "metadata": {},
   "source": [
    "**Prediction** \n",
    "\n",
    "- Categorical\n",
    "- Point estimate\n",
    "\n",
    "\n",
    "**Categorical**\n",
    "\n",
    "Categorical prediction is a supervised machine learning task that aims to predict a categorical label (or class) for a given input. The categorical labels are discrete and unordered, such as for example fruit types \"Apple,\" \"Orange,\" \"Banana,\" etc. Categorical prediction is also known as classification. After training, one can use the model to predict new data.\n",
    "\n",
    "![alt text](./images/binary_decision_problem.jpg \"Title\")\n",
    "\n",
    "![alt text](./images/4_fields.jpg \"Title\")\n",
    "\n",
    "Several algorithms can be used for categorical prediction, including:\n",
    "\n",
    "-    Logistic regression: Logistic regression models the probability of an input belonging to a particular class.\n",
    "\n",
    "-    Decision trees: A tree-based model that can be used for binary and multi-class classification. Decision trees use a set of if-then-else rules to make predictions.\n",
    "\n",
    "-    Random forests: A method that combines multiple decision trees to improve the accuracy of the predictions.\n",
    "\n",
    "-    Support Vector Machines (SVMs): A linear model that can be used for binary and multi-class classification. SVMs find the best boundary (or \"hyperplane\") that separates the classes. Note there is also a non-linear version of this method.\n",
    "\n",
    "-    Neural networks: A type of model inspired by the structure of the human brain and can be used for binary and multi-class classification. Neural networks are handy for problems with many input features or a complex decision boundary.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "16cb64f3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-11T08:49:35.038878Z",
     "start_time": "2024-12-11T08:49:32.185290Z"
    }
   },
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.metrics import accuracy_score"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "8a4f619b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-11T08:49:35.072090Z",
     "start_time": "2024-12-11T08:49:35.043436Z"
    }
   },
   "source": [
    "# Works on MyBinder or locally #\n",
    "df = pd.read_csv(\"./datasets/Group_A_B.csv\")\n"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "a20c1b55",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-11T08:49:36.048306Z",
     "start_time": "2024-12-11T08:49:35.075425Z"
    }
   },
   "source": [
    "# Works only on COLAB #\n",
    "\n",
    "\n",
    "def read_csv_from_github(url):\n",
    "    import requests\n",
    "    from io import StringIO\n",
    "    response = requests.get(url)\n",
    "    data = response.text\n",
    "    return pd.read_csv(StringIO(data))\n",
    "\n",
    "\n",
    "url = 'https://github.com/bgagl/ML_Individual_Differences/raw/5b70d36362172bb50d5be984e8c97526dda26bd2/datasets/Group_A_B.csv'\n",
    "df = read_csv_from_github(url=url)\n",
    "df.head()\n"
   ],
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "urllib3 v2.0 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with LibreSSL 2.8.3. See: https://github.com/urllib3/urllib3/issues/2168",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mImportError\u001B[0m                               Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[3], line 13\u001B[0m\n\u001B[1;32m      9\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m pd\u001B[38;5;241m.\u001B[39mread_csv(StringIO(data))\n\u001B[1;32m     12\u001B[0m url \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mhttps://github.com/bgagl/ML_Individual_Differences/raw/5b70d36362172bb50d5be984e8c97526dda26bd2/datasets/Group_A_B.csv\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m---> 13\u001B[0m df \u001B[38;5;241m=\u001B[39m \u001B[43mread_csv_from_github\u001B[49m\u001B[43m(\u001B[49m\u001B[43murl\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43murl\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     14\u001B[0m df\u001B[38;5;241m.\u001B[39mhead()\n",
      "Cell \u001B[0;32mIn[3], line 5\u001B[0m, in \u001B[0;36mread_csv_from_github\u001B[0;34m(url)\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mread_csv_from_github\u001B[39m(url):\n\u001B[0;32m----> 5\u001B[0m     \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mrequests\u001B[39;00m\n\u001B[1;32m      6\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mio\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m StringIO\n\u001B[1;32m      7\u001B[0m     response \u001B[38;5;241m=\u001B[39m requests\u001B[38;5;241m.\u001B[39mget(url)\n",
      "File \u001B[0;32m~/PycharmProjects/ML_Individual_Differences/venv/lib/python3.9/site-packages/requests/__init__.py:43\u001B[0m\n\u001B[1;32m      6\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m      7\u001B[0m \u001B[38;5;124;03mRequests HTTP Library\u001B[39;00m\n\u001B[1;32m      8\u001B[0m \u001B[38;5;124;03m~~~~~~~~~~~~~~~~~~~~~\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     38\u001B[0m \u001B[38;5;124;03m:license: Apache 2.0, see LICENSE for more details.\u001B[39;00m\n\u001B[1;32m     39\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m     41\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mwarnings\u001B[39;00m\n\u001B[0;32m---> 43\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01murllib3\u001B[39;00m\n\u001B[1;32m     45\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mexceptions\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m RequestsDependencyWarning\n\u001B[1;32m     47\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "File \u001B[0;32m~/PycharmProjects/ML_Individual_Differences/venv/lib/python3.9/site-packages/urllib3/__init__.py:38\u001B[0m\n\u001B[1;32m     32\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m     33\u001B[0m     \u001B[38;5;66;03m# fmt: off\u001B[39;00m\n\u001B[1;32m     34\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[1;32m     35\u001B[0m         \u001B[38;5;129;01mnot\u001B[39;00m ssl\u001B[38;5;241m.\u001B[39mOPENSSL_VERSION\u001B[38;5;241m.\u001B[39mstartswith(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mOpenSSL \u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     36\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m ssl\u001B[38;5;241m.\u001B[39mOPENSSL_VERSION_INFO \u001B[38;5;241m<\u001B[39m (\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m     37\u001B[0m     ):  \u001B[38;5;66;03m# Defensive:\u001B[39;00m\n\u001B[0;32m---> 38\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mImportError\u001B[39;00m(\n\u001B[1;32m     39\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124murllib3 v2.0 only supports OpenSSL 1.1.1+, currently \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     40\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mthe \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mssl\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m module is compiled with \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mssl\u001B[38;5;241m.\u001B[39mOPENSSL_VERSION\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     41\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSee: https://github.com/urllib3/urllib3/issues/2168\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     42\u001B[0m         )\n\u001B[1;32m     43\u001B[0m     \u001B[38;5;66;03m# fmt: on\u001B[39;00m\n\u001B[1;32m     44\u001B[0m \n\u001B[1;32m     45\u001B[0m \u001B[38;5;66;03m# === NOTE TO REPACKAGERS AND VENDORS ===\u001B[39;00m\n\u001B[1;32m     46\u001B[0m \u001B[38;5;66;03m# Please delete this block, this logic is only\u001B[39;00m\n\u001B[1;32m     47\u001B[0m \u001B[38;5;66;03m# for urllib3 being distributed via PyPI.\u001B[39;00m\n\u001B[1;32m     48\u001B[0m \u001B[38;5;66;03m# See: https://github.com/urllib3/urllib3/issues/2680\u001B[39;00m\n\u001B[1;32m     49\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "\u001B[0;31mImportError\u001B[0m: urllib3 v2.0 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with LibreSSL 2.8.3. See: https://github.com/urllib3/urllib3/issues/2168"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "1336f287",
   "metadata": {},
   "source": [
    "df"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "790b30a4",
   "metadata": {},
   "source": [
    "plt.hist([df[\"NoProblem\"], df[\"Problem\"]], bins=20, histtype='bar', color=['b','r'], label=['No Problem', 'Problem'])\n",
    "plt.legend()\n",
    "plt.xlabel('Measure')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Exercise** Find the optimal threshold value that divides No Problem and Problem"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "af55e9956e808ee4"
  },
  {
   "cell_type": "code",
   "id": "d1903574",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "a2aae385",
   "metadata": {},
   "source": [
    "**Metrics**\n",
    "\n",
    "- Accuracy\n",
    "![alt text](./images/accuracy.jpg \"Title\")\n",
    "\n",
    "- Specificity\n",
    "![alt text](./images/specificity.jpg \"Title\")\n",
    "\n",
    "- Precision\n",
    "![alt text](./images/precision.jpg \"Title\")\n",
    "\n",
    "- True positive rate\n",
    "![alt text](./images/true-positive-rate.jpg \"Title\")\n",
    "\n",
    "- False positive rate\n",
    "![alt text](./images/false-positive-rate.jpg \"Title\")\n",
    "\n",
    "\n",
    "Let's apply a decision boundary (i.e., cutoff value) and calculate the accuracy. Here we calculate an example for a boundary of `Measure == 0` based on a so-called Rule. Note rule-based systems are the simplest prediction models with the advantage that the models are highly transparent and have a high explainability. \n",
    "\n",
    "1. We must convert our data frame from wide to long format. This is a central preprocessing step, as all machine learning models we use here work only with long-format data."
   ]
  },
  {
   "cell_type": "code",
   "id": "0625e939",
   "metadata": {},
   "source": [
    "df_long = pd.melt(df, id_vars=None, value_vars=['NoProblem', 'Problem'], var_name='Group', value_name='Measure')\n",
    "df_long"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "7fef8822",
   "metadata": {},
   "source": [
    "2. Then we apply the rule to our data and create a prediction of which group a person is given a specific measure."
   ]
  },
  {
   "cell_type": "code",
   "id": "4c4bb09c",
   "metadata": {},
   "source": [
    "df_long[\"Predicted Group\"] = \"NoProblem\"\n",
    "df_long[\"Predicted Group\"][df_long[\"Measure\"] > 0] = \"Problem\"\n",
    "df_long"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "b8c0c85d",
   "metadata": {},
   "source": [
    "3. We compare the predicted group with the actual group on the accuracy metric"
   ]
  },
  {
   "cell_type": "code",
   "id": "42998715",
   "metadata": {},
   "source": [
    "true_positive = len(df_long[df_long[\"Group\"]==df_long[\"Predicted Group\"]][df_long[\"Group\"] == \"Problem\"])\n",
    "true_positive"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8eb35d87",
   "metadata": {},
   "source": [
    "true_negative = len(df_long[df_long[\"Group\"]==df_long[\"Predicted Group\"]][df_long[\"Group\"] == \"NoProblem\"])\n",
    "true_negative"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "4f676385",
   "metadata": {},
   "source": [
    "false_positive = len(df_long[df_long[\"Group\"]!=df_long[\"Predicted Group\"]][df_long[\"Group\"] == \"Problem\"])\n",
    "false_positive"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c91f513e",
   "metadata": {},
   "source": [
    "false_negative = len(df_long[df_long[\"Group\"]!=df_long[\"Predicted Group\"]][df_long[\"Group\"] == \"NoProblem\"])\n",
    "false_negative"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "bd0a38fa",
   "metadata": {},
   "source": [
    "pd.DataFrame(\n",
    "    {\n",
    "        \"Group: Problem\": [true_positive, false_positive],\n",
    "              \"Group: No Problem\": [false_negative, true_negative],\n",
    "              \"Predicted\": [\"Problem\", \"No Problem\"]\n",
    "    }\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "58366dc8",
   "metadata": {},
   "source": [
    "**Accuracy**\n",
    "![alt text](./images/accuracy.jpg \"Title\")"
   ]
  },
  {
   "cell_type": "code",
   "id": "82b1f576",
   "metadata": {},
   "source": [
    "(true_positive+true_negative) / (true_positive+true_negative+false_negative+false_positive)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "bbd451c7",
   "metadata": {},
   "source": [
    "**False positive rate**\n",
    "![alt text](./images/false-positive-rate.jpg \"Title\")\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "726516f7",
   "metadata": {},
   "source": [
    "false_positive / (true_negative+false_positive)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "be012ecf",
   "metadata": {},
   "source": [
    "**Exercise** Apply your best guess decision boundary to the dataset and estimate the Accuracy and the Specificity metric"
   ]
  },
  {
   "cell_type": "code",
   "id": "9cbaa6ad",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "5db98f10",
   "metadata": {},
   "source": [
    "**First Machine Learning Example: Logistic Regression**\n",
    "\n",
    "Let's use a logistic regression model to learn the optimal decision boundary for our problem. \n",
    "\n",
    "![alt text](./images/log_reg.jpg \"Title\")\n",
    "\n",
    "Remember the overall framework. As a first step, we will learn and predict the existing labels. When this would not result in an accuracy > .5, one would learn that the current measure is not predictive of our labels. If the accuracy is between .5 and 1, we know there is a relation between our measure and our labels. \n",
    "\n",
    "\n",
    "![alt text](./images/ml_basics.jpg \"Title\")\n",
    "\n",
    "\n",
    "First, we need to do a data transformation."
   ]
  },
  {
   "cell_type": "code",
   "id": "783a7434",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "X = df_long[\"Measure\"].values.reshape(-1, 1)\n",
    "y = df_long[\"Group\"]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "0a838bc3",
   "metadata": {},
   "source": [
    "Define the model type and fit the model on the data. "
   ]
  },
  {
   "cell_type": "code",
   "id": "104bed1a",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "clf = LogisticRegression()\n",
    "clf.fit(X, y)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "78134f53",
   "metadata": {},
   "source": [
    "After that, we predict the labels based on our measure and the fitted model. For metrics estimations, we store the prediction in our data frame."
   ]
  },
  {
   "cell_type": "code",
   "id": "b77a2030",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "df_long[\"Predicted Group: Model\"] = clf.predict(X)\n",
    "df_long"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "f52a98c7",
   "metadata": {},
   "source": [
    "Now we estimate the accuracy of the model predictions to compare the fitted model to our models. "
   ]
  },
  {
   "cell_type": "code",
   "id": "c9d4a6b4",
   "metadata": {},
   "source": [
    "true_positive = len(df_long[df_long[\"Group\"]==df_long[\"Predicted Group: Model\"]][df_long[\"Predicted Group: Model\"] == \"Problem\"])\n",
    "false_positive = len(df_long[df_long[\"Group\"]!=df_long[\"Predicted Group: Model\"]][df_long[\"Predicted Group: Model\"] == \"Problem\"])\n",
    "true_negative = len(df_long[df_long[\"Group\"]==df_long[\"Predicted Group: Model\"]][df_long[\"Predicted Group: Model\"] == \"NoProblem\"])\n",
    "false_negative = len(df_long[df_long[\"Group\"]!=df_long[\"Predicted Group: Model\"]][df_long[\"Predicted Group: Model\"] == \"NoProblem\"])\n",
    "(true_positive+true_negative) / (true_positive+true_negative+false_negative+false_positive)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "3869019e",
   "metadata": {},
   "source": [
    "The `score()` function is also doing the same thing."
   ]
  },
  {
   "cell_type": "code",
   "id": "d2a57643",
   "metadata": {},
   "source": [
    "clf.score(X, y)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "5c434adc",
   "metadata": {},
   "source": [
    "So in comparison to our model, the accuracy of the fitted model is higher. \n",
    "\n",
    "To get the boundary of our model, we can now look at, e.g., the minimum value of the \"Problem\" Group. "
   ]
  },
  {
   "cell_type": "code",
   "id": "5f4db2c2",
   "metadata": {},
   "source": [
    "min(df_long[\"Measure\"][df_long[\"Predicted Group: Model\"]==\"Problem\"])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "872278a5",
   "metadata": {},
   "source": [
    "To get a better picture, we can now look at the histogram again, showing the result of the model prediction. "
   ]
  },
  {
   "cell_type": "code",
   "id": "4d6d7d63",
   "metadata": {},
   "source": [
    "plt.hist([df_long[\"Measure\"][df_long[\"Predicted Group: Model\"]==\"NoProblem\"], \n",
    "         df_long[\"Measure\"][df_long[\"Predicted Group: Model\"]==\"Problem\"]], \n",
    "         bins=20, histtype='bar', color=['b','r'], label=['No Problem', 'Problem'])\n",
    "plt.legend()\n",
    "plt.xlabel('Measure')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "5dae01f4",
   "metadata": {},
   "source": [
    "The `0.87` value is the best solution the model could find. Considering that the accuracy is the highest. \n",
    "\n",
    "**Exercise** Think about that approach and what might be problems here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba6e510",
   "metadata": {},
   "source": [
    "**Train-Test split**\n",
    "\n",
    "The train-test split is an essential step in the machine-learning process because it allows you to evaluate your model's performance on unseen data.\n",
    "When you train a machine learning model, you use a dataset to fit the model's parameters to the data. This process is known as training the model. However, using the same data to evaluate the model's performance may achieve high accuracy because it has seen the data before. This phenomenon is known as overfitting. Here the model learned the noise in the training data so that it may perform poorly on new, unseen data.\n",
    "To overcome this problem, you can split your data into training and test sets. The training set is used to fit the model's parameters, while the test set is used to evaluate the model's performance on unseen data. This allows you to estimate the model's performance on new data and compare different models' performance.\n",
    "\n",
    "To implement this we use the `train_test_split` function from sklearn. The `test_size` parameter allows you to define the amount of data in the test set in percent (i.e., `0.2` is 20\\%)."
   ]
  },
  {
   "cell_type": "code",
   "id": "da524dbe",
   "metadata": {},
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "print(len(y_train))\n",
    "len(y_test)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "73c8aa4a",
   "metadata": {},
   "source": [
    "Then we fit the model only on the train data and score it on the test data."
   ]
  },
  {
   "cell_type": "code",
   "id": "63b1cdbc",
   "metadata": {},
   "source": [
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(clf.score(X_train, y_train))\n",
    "print(clf.score(X_test, y_test))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "7f83c655",
   "metadata": {},
   "source": [
    "The score on the training data indicates if we can learn something from the data and the test data indicates if the model can generalize to new data.  \n",
    "\n",
    "\n",
    "So lets do this again but with a differen classificatioin algorithm. So that one can compare models. The `RandomForestClassifier` function allows to fit a random forest model. "
   ]
  },
  {
   "cell_type": "code",
   "id": "def1b445",
   "metadata": {},
   "source": [
    "clf = RandomForestClassifier(n_estimators=100, max_depth=3, random_state=0)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "7cd6de44",
   "metadata": {},
   "source": [
    "And now we can look a the model performance again"
   ]
  },
  {
   "cell_type": "code",
   "id": "3ab9ba18",
   "metadata": {},
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(clf.score(X_train, y_train))\n",
    "print(clf.score(X_test, y_test))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "64a9e579",
   "metadata": {},
   "source": [
    "**Exercise** Define a decision tree classifier `DecisionTreeClassifier()` and compare the performance to the other two models."
   ]
  },
  {
   "cell_type": "code",
   "id": "18abfd80",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "b7b2cdd5",
   "metadata": {},
   "source": [
    "**Cross Validation**\n",
    "\n",
    "Cross-validation allows you to evaluate your model's performance on multiple subsets of your data rather than just a single train-test split. Therefore it provides a more robust estimate of your model's performance and reduces the risk of overfitting (i.e., Regulization method).\n",
    "\n",
    "![alt text](./images/regularization.jpg \"Title\")\n",
    "\n",
    "Cross validation is a good and easy method to reduce the possibility of overfitting. \n",
    "\n",
    "![alt text](./images/cv_figure.jpg \"Title\")\n",
    "\n",
    "Define the cross-validation method. Here we used the `KFold` method. The parameter `n_splits` allows the sprecification of the number of equal sized random splits (e.g., `n_splits=5` defines that the data will be split in 5 equal sized data parts including randomly drawn cases)."
   ]
  },
  {
   "cell_type": "code",
   "id": "47ef847b",
   "metadata": {},
   "source": [
    "cv = KFold(n_splits=5)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "eca53352",
   "metadata": {},
   "source": [
    "Compute cross-validated accuracy scores. Here the arithmetic mean of the five scores accros all folds is calculated."
   ]
  },
  {
   "cell_type": "code",
   "id": "79f777bc",
   "metadata": {},
   "source": [
    "scores = cross_val_score(clf, X, y, cv=cv, n_jobs=-1)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "0bdab37d",
   "metadata": {},
   "source": [
    "clf"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "90af24ba",
   "metadata": {},
   "source": [
    "Print the mean and standard deviation of the accuracy scores"
   ]
  },
  {
   "cell_type": "code",
   "id": "f0119681",
   "metadata": {},
   "source": [
    "print(np.mean(scores), np.std(scores))\n",
    "scores"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "d9cc4e67",
   "metadata": {},
   "source": [
    "**Exercise** Do the Cross-Validation for the three methods we used above and present the scores in a box-plot side by side."
   ]
  },
  {
   "cell_type": "code",
   "id": "09eddf82",
   "metadata": {},
   "source": [
    "data = {'Random Forest': scores}\n",
    "df = pd.DataFrame(data)\n",
    "plt.boxplot(df)\n",
    "plt.xlabel('Datasets')\n",
    "plt.ylabel('Values')\n",
    "plt.ylim(0.5, 1)\n",
    "#plt.xticks([1, 2], df.columns.tolist())\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f43a20e9",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "58a6990e",
   "metadata": {},
   "source": [
    "In a final example, like in the figure above, we first split into training and test set and then estimate the parameters within a five fold cross-validation. The model that results from the cross-validation is then used to categorize the testdata.\n",
    "\n",
    "First we define a classifier. "
   ]
  },
  {
   "cell_type": "code",
   "id": "74ae2951",
   "metadata": {},
   "source": [
    "clf = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=0)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "d607e265",
   "metadata": {},
   "source": [
    "Do the train/test split with 80%/20% of the data."
   ]
  },
  {
   "cell_type": "code",
   "id": "09e4b5cc",
   "metadata": {},
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "265b3366",
   "metadata": {},
   "source": [
    "Next we train the classifier without cross-validation and score the fitted random forest to learn if the data holds patterns that can be trained."
   ]
  },
  {
   "cell_type": "code",
   "id": "47b3bab5",
   "metadata": {},
   "source": [
    "clf.fit(X_train, y_train)\n",
    "noCV_score = clf.score(X_train, y_train)\n",
    "print(\"Score without CV: {}\".format(noCV_score))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "b2f9ed93",
   "metadata": {},
   "source": [
    "Next step is to get a model based on parameters after implementing a cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "id": "bf6796de",
   "metadata": {},
   "source": [
    "scores = cross_val_score(clf, X_train, y_train, cv=5)\n",
    "\n",
    "print(\"Cross-validation scores: {}\".format(scores))\n",
    "print(\"Average score: {:.2f}\".format(scores.mean()))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "a8d27bc4",
   "metadata": {},
   "source": [
    "Final step is to score the model with the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "id": "bbe56edc",
   "metadata": {},
   "source": [
    "y_pred = clf.predict(X_test)\n",
    "print(\"Score on test data with CV model: {}\".format(accuracy_score(y_pred,y_test)))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "74eb1c7a",
   "metadata": {},
   "source": [
    "In the end, we have three parameters. Accuracy on the training data with and without cross-validation and the score on the left out test data. \n",
    "\n",
    "**Exercise** Describe in one or two sentences what we learn from the three accuracy measures."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca2d4a1",
   "metadata": {},
   "source": [
    "- \n",
    "-\n",
    "-"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
